# -*- coding: utf-8 -*-
"""GTU CaseStudy  ML Project 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U5ulsIlUcM8WAPNMPh3cVVyjE4rnPMXB

**GTU Case Study**

* Task: To Create Smart Tool Help to Recoginze Best Candidate Early
* Offer Right Number Of Scholarships without Running out of money
* Send Offer Students earliar so they get their visas on time

**Step # A**

 **Import Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""**Step # B**

**Upload  Dataset**
"""

from google.colab import drive
drive.mount('/content/drive')

# Read the data
df = pd.read_csv("/content/Admission_Predict.csv")

df

"""**STEP # 1**

**Data Explore**
"""

df.shape #400 rows, 9 columns (8 Inputs, 1 Output)

df.head(20)

df.info()

df.isnull().sum() # For missing values

"""# Implies value.count function
it's help to analyze column in a way to check whether it's countinous in nature or categorical.
Also it tell us about number of unique values in that particular column with count which tell us about how many time that unique value repeated which help to identify the column is countinous or categorical.
"""

df['SOP'].value_counts() #After analysis it's categoriacl cuz having less then 10 unique values

df['Research'].value_counts()

df.columns

df['CGPA'].value_counts()

df['LOR '].value_counts()

"""So, here CGPA is clearly shown after value count that it is countinous in nature
mean while SOP,LOR,Research is categrical in nature
"""

df.describe()

"""**Structure to visualize statistical overview**

**count:** It tells about how many actual data points are present in that column.If the count is less than the total rows, it means some missing (NaN) values exist in that column.

**Mean & Q3:** help to visualize about the distribution like clue like either distribution is normal or not

**Std:** Help us to detect ouliears in column how much like about average estimate of outliears detect in each column

**min/max :** help also tell us about outliears in more depth like dive into data and tell and detect outliers near or far to Q1 to min and Q3 to max

* If we consider output it shows that there is **NO MISSING** values as count value of each column is equal to number of rows.

* So **by compare Mean & Max** it indicate that there is just **20 to 25%** **difference between both of them by passing every column, which gernally indicate that features are **not heavily skewed** and or has **no extreme outliers.**

It's just statistical based summary as if we want more clarity we considered hist plot or box plot concepts to detect them visually.

Now Implies **Drop Function on Serial.no**, cus it's just for general purpose in dataset as we prepare data for model traning it may make process further complex.
"""

df.drop('Serial No.',axis=1,inplace=True) # inplace = True is consider to fix operation in dataset / axis = 1 implies operation on column

df

"""Here, Serial.no column is sucessfully deleted

#**Duplication**
"""

df.duplicated().sum()

"""* Difference Between** df.duplicated()** and **df.duplicated().sum()**

Basically duplication operation in pandas is for rows it work in two ways

![image.png](data:image/png;base64,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)

**df.duplicated():** Check which rows are duplicates

**df.duplicated().sum():** Count how many duplicates
"""

x_columns = ['GRE Score','TOEFL Score','CGPA']

df[x_columns].plot(kind='box', subplots=True, layout=(2, 4), figsize=(15, 10))

plt.tight_layout()
plt.show()

"""* I consider GRE, TOFEL, CGPA cuz these are countinous in nature
* Rest SOP, LOR, Research, Rating all are categorical in nature
* And at last, Chance of admission is our targeted variable.

**Outliears History:**
 Now according to domain knowledge if i analyze this columns so i can say that it's oaky to be not tackle them because Score criteria is okay to be exceed from range cause it's vary from person to person. It's not impact in a way of any sort of error either it's help to analysis Best Candidate Earlier.

 So after all i observe that not all outliears are bad some are usefull if we analyze it on basis of realworld problems.

#**Categorical Column Analysis**
In most cases outliers are not need to be removed in categorical columns because due to there hirerchy or binary in nature there is less chance to detect error points as on the other hand continous ones, are quntitative in nature so they have high probability of low or high extreme values.

Same but slightly different of categorical on & off there will be cases find where we have to consider outliear

So i gona observe cate columns of the dataset i have let see what we got...
"""

x_columns = ['University Rating', 'SOP',
       'LOR ', 'Research', 'Chance of Admit ']

df[x_columns].plot(kind='box', subplots=True, layout=(2, 4), figsize=(15, 10))

plt.tight_layout()
plt.show()

"""So,
University Rating, SOP has no outliears.

Where as LOR, Chance of Admission have outliears but it's okay to not to be removed cuz according to domain aspect this feature based on person and perfomance vary on basis of their commitments and chance of admission is also based on their overall acedemic & personal perfomance.

If we consider Research plot seems unusuall because it's categorical (nominal) & binary in nature have 0,1 values in columns and most of students there with having their research work.

#**Outliear Filteration process**
"""

col = 'LOR '

# Calculate Q1, Q3 and IQR
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Find outliers
outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

# Print results
print("Number of outliers:", outliers.shape[0])
print(outliers)

"""**PURPOSE OF DATA HANDLING BY IMPLIES OULIEAR FILTER:**
* As responsibility while explore data to try to deep dive so we provide clean prepare dataset to model for traning for that **after analyze outilear we filter those columns where we detect outliears just to ensure that ouliear we get on whcih basis is it valid or some time as it's a process of passing multiple application will data enter properly so for this sort of deep analysis Ouliear filter process is helpfull even we just want statics or we review that after visualization**
"""

col = 'CGPA'

# Calculate Q1, Q3 and IQR
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Find outliers
outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

# Print results
print("Number of outliers:", outliers.shape[0])
print(outliers)

"""#**Check Inconsistancies in data**

* **This is the process where we analyze that the info we have is in proper way either it's formate for text or date formate also for lower & upper case (Case Sensitive), datatype, empty spaces, missing values, repated data (duplication), outliears etc**.

* **-->** for that we consider **df[column].unique()** and many other according to required used scenerious like .replace(), .astype(), .strip(), lower(), etc.

* For any other implementation first we implies **unique()** operation to detect then to resolve we consider rest required operation as shown above.

**!! Warning:** As we done process of Outliear detection via box plot and filteration process so the process of Check inconsistance it's good for small dataset instead of large and complex as for the large set where we, consider process like box plot and outliears filteration process.

We though use this in large dataset as well but when a analyst is required to analyze dataset through different aspects and might they will think that he/she will be crack misshandling through this batch visualization process.
"""

df['GRE Score'].unique()

df['CGPA'].unique()

df['Research'].unique()

"""**So, in all above columns after explore data inconsistances >>>**
* No datatype issue
* No unneccessary repeated rows(just required one is their)
* No missing values like NaN,0,-1 etc
* No percentage mixed up (Wrong Scale)
* Yes, Outlier Detected as we already explore above in CGPA Column.

#**Histogram**
"""

# Plot the histograms for all numerical features at once
df.hist(bins=20, figsize=(15, 10))
plt.tight_layout()
plt.show()

"""**GRE Score:** Normally Distributed.

**TOEFL Score:** Mainly Normally distributed.

**University Rating:** As it's categorical the reasons it show difference in plot rest it is discrete distribution.

**SOP:** -ive skewed

**LOR:** -ive skewed

**CGPA:** -ive skewed

**Research:** as it's based on binary and have categorical so it's high on 1 and minimal down at 0.
  
**Chance of Admission:** -ive skewed

#**Scatter Plot**
A scatter plot is a **2D graph that shows the relationship between two numerical variables using dots.**

The spread or pattern of these dots helps us understand the nature of their relationship.
* If the **dots** form a **straight-line pattern**, it indicates a** linear relationship.**
* If they are **scattered without any pattern**, it **suggests no strong correlation.**
"""

for a in df.columns:
  plt.figure(figsize=(2,2))
  plt.scatter(df[a], df["Chance of Admit "])
  plt.xlabel(a)
  plt.ylabel("Chance of Admit")

  plt.show()

"""Here, **Countinous columns create strongest Co-relation with Target Variavble 'Chance of Admission'**.
*Rest Categorical seems okay but here more grip get by countinous.

#**Scatter Matrix Path from EDA TO ML MODEL TRAINING**

* 1. It is specifically for numeric columns if data in categoriacl column in (Text) after imputation of encoding those columns are eligible to consider their. Since scatter plots are based on coordinate axes, this technique only works with numeric data types (like int or float). Categorical (text) columns must be dropped or encoded  but generally,scatter matrix is not used for them.

* 2. Scatter matrix (or pair plot) helps visualize relationships between all columns one by one showing how each feature interacts with the others.

* 3. The visual patterns help in deciding which machine learning models might suit the dataset — for example, linear relationships favor Linear Regression, while scattered or grouped data might perform better with Decision Trees, Random Forests, or KNN.

* 4. It also supports feature selection by identifying which columns show strong, weak, or no correlation — guiding what to include in training.

    **This all are basic Four aspects of Scatter Matrix.**
"""

sns.pairplot(df)
plt.show()

"""# **STEP # 2 Feature Engineering**

# **Correlation Heatmap**

* Correlation helps us identify which **input (independent) variables** have the strongest relationship **(bond)** with the output **(target)** variable.
"""

plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""# **Min-Max Scaling (Normalization)**


"""

df

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_scaled = scaler.fit_transform(df)
df_scaled[0] #Shows the first row as an 1D array

#Covert to data frame
df_scaled = pd.DataFrame(df_scaled, columns = df.columns)
df_scaled

"""**Histogram after Scaling**"""

df_scaled.hist(figsize=(20,20))
plt.show()

"""In Comparision, before Scaling Histogram now features are scaled and ready to proceed for Model Traning

# **Standard Scaling (Z-score Normalization)**

* **scaler = StandardScaler()**
Creates a scaler to standardize data.

* **df_scaled = scaler.fit(df)**
Calculates the mean and standard deviation for each column but doesn’t change the data yet.

To actually scale the data, as we required;

* **df_scaled = scaler.fit_transform(df)**
This changes the data to have mean = 0 and standard deviation = 1.
"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = scaler.fit(df)
df_scaled

"""# **STEP # 3 MODEL TRAINING**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

features = ['GRE Score', 'TOEFL Score', 'CGPA', 'University Rating', 'SOP', 'LOR ', 'Research']
target = 'Chance of Admit '

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Linear Regression**"""

lr = LinearRegression()
lr.fit(X_train, y_train)
lr_preds = lr.predict(X_test)

"""# **Decision Tree Regressor**"""

dt = DecisionTreeRegressor(max_depth=4, random_state=42)
dt.fit(X_train, y_train)
dt_preds = dt.predict(X_test)

"""# **Random Forest Regressor**"""

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_preds = rf.predict(X_test)

"""# **Evaluation Metrics**"""

print("Linear Regression MSE:", mean_squared_error(y_test, lr_preds))
print("Linear Regression R2:", r2_score(y_test, lr_preds))

print("Decision Tree MSE:", mean_squared_error(y_test, dt_preds))
print("Decision Tree R2:", r2_score(y_test, dt_preds))

print("Random Forest MSE:", mean_squared_error(y_test, rf_preds))
print("Random Forest R2:", r2_score(y_test, rf_preds))

"""# **Feature Importance from Random Forest**"""

importances = pd.Series(rf.feature_importances_, index=features).sort_values()
importances.plot(kind='barh', title='Feature Importance (Random Forest)')
plt.show()

"""# **Decision Tree Visualization**"""

plt.figure(figsize=(16, 8))
plot_tree(dt, feature_names=features, filled=True, rounded=True)
plt.title("Decision Tree - Admission Logic")
plt.show()

"""# **Hypothetical Applicant Prediction**"""

applicant_data = pd.DataFrame([{
    'GRE Score': 322,
    'TOEFL Score': 111,
    'CGPA': 8.9,
    'University Rating': 3,
    'SOP': 4,
    'LOR ': 4,
    'Research': 1
}])

#Linear Regression
lr_app_pred = lr.predict(applicant_data)[0]

#Decision Tree Regressor
dt_app_pred = dt.predict(applicant_data)[0]

#Random Forest Regressor
rf_app_pred = rf.predict(applicant_data)[0]

print(f"Applicant predicted admit probability (Linear Regression): {lr_app_pred:.2f}")
print(f"Applicant predicted admit probability (Decision Tree): {dt_app_pred:.2f}")
print(f"Applicant predicted admit probability (Random Forest): {rf_app_pred:.2f}")

"""# **Scholarship Recommendation Logic**"""

if rf_app_pred > 0.70 and applicant_data['CGPA'].values[0] >= 8.5:
    print("Recommend for scholarship.")
else:
    print("Do not recommend for scholarship.")

import pickle
import os

# Define the directory path
output_dir = '/content/drive/MyDrive/MlProject/'

# Create the directory if it doesn't exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Assume model is your trained ML model (using the correct variable name 'rf')
with open(os.path.join(output_dir, 'my_modelGTU.pkl'), 'wb') as file: # Save to a specific directory
        pickle.dump(rf, file)